// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

import dynamicProto from "@microsoft/dynamicproto-js";
import {
    INotificationManager, IProcessTelemetryContext, IUnloadHookContainer, eBatchDiscardedReason, getGlobal, getJSON, isNotNullOrUndefined,
    onConfigChange
} from "@microsoft/applicationinsights-offlinechannel-js/node_modules/@microsoft/applicationinsights-core-js";
// import { IPromise, createAsyncRejectedPromise } from "@nevware21/ts-async";
import {
    ILocalStorageProviderContext, IOfflineChannelConfiguration, IOfflineProvider, IStorageJSON, IStorageTelemetryItem
} from "../Interfaces/IOfflineProvider";
import { PayloadHelper } from "../PayloadHelper";
import AsyncStorage from '@react-native-async-storage/async-storage';

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

import { EventPersistence } from "@microsoft/applicationinsights-common";
import {
    INotificationManager, ITelemetryItem, NotificationManager, eLoggingSeverity, generateW3CId
} from "@microsoft/applicationinsights-core-js";
import { isNumber, isString, objKeys, strSubstr } from "@nevware21/ts-utils";
import { IPostTransmissionTelemetryItem } from "../Interfaces/IInMemoryBatch";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

import { EventPersistence } from "@microsoft/applicationinsights-common";
import {
    INotificationManager, IPayloadData, IProcessTelemetryContext, IXHROverride, createEnumStyle
} from "@microsoft/applicationinsights-core-js";
import { IPromise } from "@nevware21/ts-async";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

import dynamicProto from "@microsoft/dynamicproto-js"
import {
    IDiagnosticLogger, _eInternalMessageId, _throwInternal, eLoggingSeverity, isFunction
} from "@microsoft/applicationinsights-core-js";
import { base64Decode, base64Encode } from "./Helpers/Utils";
import { IStorageTelemetryItem } from "./Interfaces/IOfflineProvider";

export class PayloadHelper {

    constructor(logger: IDiagnosticLogger) {
        dynamicProto(PayloadHelper, this, (_self) => {
            /**
             * Deserializes the current stringto a JSON object.
             */
            _self.base64ToArr = (input: IStorageTelemetryItem): IStorageTelemetryItem => {
                if (!input || !input.isArr) {
                    return input;
                }
             
                try {
                    let data = input.data;
                    if (data) {
                        input.data = base64Decode(data as any);
                    }
                    return input;
                } catch (e) {
                    // if serialization fails return an empty string
                    _throwInternal(logger, eLoggingSeverity.CRITICAL, _eInternalMessageId.CannotSerializeObject, (e && isFunction(e.toString)) ? e.toString() : "Error serializing object", null, true);
                }
                return null;
                
            }

            _self.base64ToStr = (item: IStorageTelemetryItem): IStorageTelemetryItem => {
                if (!item || !item.isArr) {
                    return item;
                }
                
                try {
                    let data = item.data;
                    if (data) {
                        item.data = base64Encode(data as any);
                    }
                    return item;
                } catch (e) {
                    // if serialization fails return an empty string
                    _throwInternal(logger, eLoggingSeverity.CRITICAL, _eInternalMessageId.CannotSerializeObject, (e && isFunction(e.toString)) ? e.toString() : "Error serializing object", null, true);
                }
                return null;
               
            }
            
        });
    }

    /**
     *  Decode the JSON string back to Uint8 array.
     */
    public base64ToArr(input: IStorageTelemetryItem): IStorageTelemetryItem {
        // @DynamicProtoStub -- DO NOT add any code as this will be removed during packaging
        return null;
    }

    /**
     * Code the Uint8 array object to string.
     */
    public base64ToStr(item: IStorageTelemetryItem): IStorageTelemetryItem {
        // @DynamicProtoStub -- DO NOT add any code as this will be removed during packaging
        return null;
    }
}

/**
 * Identifies the Storage Providers used by the LocalStorageChannel
 */
export const enum eStorageProviders {
    /**
     * Identifies that the provider that uses (window||globalThis||self).localStorage
     */
    LocalStorage = 1,

    /**
     * Identifies that the provider that uses (window||globalThis||self).sessionStorage
     */
    SessionStorage = 2,

    /**
     * Identifies that the provider that uses (window||globalThis||self).indexedDB
     */
    IndexedDb = 3
}

export const StorageProviders = (/* @__PURE__ */ createEnumStyle<typeof eStorageProviders>({
    LocalStorage: eStorageProviders.LocalStorage,
    SessionStorage: eStorageProviders.SessionStorage,
    IndexedDb: eStorageProviders.IndexedDb
}));
export type StorageProviders = number | eStorageProviders;

/**
 * The IOfflineChannelConfiguration interface defines the configuration options for offline channel,
 * supports offline events storage, retrieval and re-sending.
 */
export interface IOfflineChannelConfiguration {
    /**
     * [Optional] The max size in bytes that should be used for storing events(default up to 5 Mb) in local/session storage.
     * The maximum size in bytes that should be used for storing events in storage If not specified, the system will use up to 5 MB
     * @default 5000000
     */
    maxStorageSizeInBytes?: number;

    /**
     * [Optional] The storage key prefix that should be used when storing events in persistent storage.
     * @default AIOffline
     */
    storageKeyPrefix?: string;

    /**
     * [Optional] Identifies the minimum level that will be cached in the offline channel. Valid values of this
     * setting are defined by the EventPersistence enum, currently Normal (1) and Critical (2) with the default
     * value being Normal (1), which means all events without a persistence level set or with invalid persistence level will be marked as Normal(1) events.
     * @default 1
     */
    minPersistenceLevel?: number | EventPersistence;

    /**
     * [Optional] Identifies the StorageProviders that should be used by the system if available, the first available
     * provider will be used. Valid available values are defined by the eStorageProviders enum. Only the first 5 entries
     * are processed, so if this value contains more than 5 elements they will be ignored.
     * Note: LocalStorage will be used to save unload events even if it is not in the providers list
     * Default order is [StorageProviders.LocalStorage, StorageProviders.IndexedDB]
     */
    providers?: number[] | eStorageProviders[];

    /**
     * [Optional] The IndexedDb database name that should be used when storing events using (window||globalThis||self).indexedDb.
     */
    indexedDbName?: string;

    /**
     * [Optional] Identifies the maximum number of events to store in each memory batch before sending to persistent storage.
     * For versions > 3.3.2, new config  splitEvts is added
     * If splitEvts is set true, eventsLimitInMem will be applied to each persistent level batch
     */
    eventsLimitInMem?: number;

    /**
     * [Optional] Identifies if events that have existed in storage longer than the maximum allowed time (configured in inStorageMaxTime) should be cleaned after connection with storage.
     * If not provided, default is false
     */
    autoClean?: boolean;

    /**
     * [Optional] Identifies the maximum time in ms that items should be in memory before being saved into storage.

     * @default 15000
     */
    inMemoMaxTime?: number;

    /**
     * [Optional] Identifies the maximum time in ms that items should be in persistent storage.
     * default: 10080000 (around 2.8 hours) for versions <= 3.3.0
     * default: 604800000 (around 7days) for versions > 3.3.0
     */
    inStorageMaxTime?: number;

    /**
     * [Optional] Identifies the maximum retry times for an event batch.
     * default: 1
     */
    maxRetry?: number;

    /**
     * Identifies online channel IDs in order. The first available one will be used.
     * default is [AppInsightsChannelPlugin, PostChannel]
     */
    primaryOnlineChannelId?: string[];

    /**
     * Identifies the maximum size per batch in bytes that is saved in persistent storage.
     * default 63000
     */
    maxBatchsize?: number;

    /**
     * Identifies offline sender properties. If not defined, settings will be the same as the online channel configured in primaryOnlineChannelId.
     */
    senderCfg?: IOfflineSenderConfig;

    /**
     * Identifies the interval time in ms that previously stored offline event batches should be sent under online status.
     * default 15000
     */
    maxSentBatchInterval?: number;

    /**
     * Identifies the maximum event batch count when cleaning or releasing space for persistent storage per time.
     * default 10
     */
    EventsToDropPerTime?: number;

    /**
     * Identifies the maximum critical events count for an event batch to be able to drop when releasing space for persistent storage per time.
     * default 2
     */
    maxCriticalEvtsDropCnt?: number;

    /**
    * Identifies overridden for the Instrumentation key when the offline channel calls processTelemetry.
    */
    overrideInstrumentationKey?: string;

    /**
     * Identifies when saving events into the persistent storage, events will be batched and saved separately based on persistence level
     * this is useful to help reduce the loss of critical events during cleaning process
     * but it will result in more frequest storage implementations.
     * If it is set to false, all events will be saved into single in memory batch
     * Default: false
     */
    splitEvts?: boolean;


    /**
     * [Optional] Custom provider that can be used instead of the provided LocalStorage, SessionStorage, IndexedDB.
     * Default: null
     * @since 3.9.10
     */
    customProvider?: IOfflineProvider;

    /**
     * [Optional] Custom unload provider should be used for handling unload scenarios.
     * This provider should support synchronous operations (supportsSyncRequests should return true)
     * If the unload provider is not provided, the provided customProvider will be used if it supports sync requests,
     * otherwise localStorage will be used by default.
     * Default: null
     * @since 3.9.10
     */
    customUnloadProvider?: IOfflineProvider;

    //TODO: add do sampling
   
}

export interface IOfflineSenderConfig {

    /**
     * Identifies status codes for re-sending event batches
     * Default: [401, 403, 408, 429, 500, 502, 503, 504]
     */
    retryCodes?: number[];

    /**
     * [Optional] Either an array or single value identifying the requested TransportType type(s) that should be used for sending events
     * If not defined, the same transports will be used in the channel with the primaryOnlineChannelId
     */
    transports?: number | number[];

    /**
     * [Optional] The HTTP override that should be used to send requests, as an IXHROverride object.
     */
    httpXHROverride?: IXHROverride;

    /**
     * Identifies if provided httpXhrOverride will always be used
     * default false
     */
    alwaysUseXhrOverride?: boolean;
}

/**
 * An internal interface which defines web provider Storage JSON details
 */
export interface IStorageJSON {
    
    /**
     * The timestamp at which the storage was last accessed.
     */
    lastAccessTime?: number;
    evts?: { [id: string]: IStorageTelemetryItem }; // id is the timestamp value
}

/**
 * An internal interface which defines a common storage item
 */
export interface IStorageTelemetryItem extends IPayloadData {
    id?: string;
    iKey?: string;
    sync?: boolean;
    criticalCnt?: number;
    isArr?: boolean;
    attempCnt?: number;
}


/**
 * An internal interface which defines a common provider context that is used to pass multiple values when initializing provider instances
 */
export interface ILocalStorageProviderContext {
    /**
     * Identifies the context for the current event
     */
    itemCtx?: IProcessTelemetryContext;

    /**
     * Identifies the local storage config that should be used to initialize the provider
     */
    storageConfig: IOfflineChannelConfiguration;

    /**
     * Identifies the unique identifier to be used for this provider instance, when not provided a new Guid will be generated for this instance.
     * This value must be unique across all instances to avoid polluting events between browser / tabs instances as they may share the same persistent storage.
     * The primary use case for setting this value is for unit testing.
     */
    id?: string;

    /**
     * Identifies endpoint url.
     */
    endpoint?: string;

    /**
     * Identifies Notification Manager
     */
    notificationMgr?: INotificationManager;
}

/*
 * An internal interface to provide access to different local storage options
 */
export interface IOfflineProvider {
    /**
     * Initializes the provider using the config
     * @param providerContext - The provider context that should be used to initialize the provider
     * @returns True if the provider is initialized and available for use otherwise false
     */
    initialize(providerContext: ILocalStorageProviderContext): boolean;

    /**
     * Identifies whether this storage provider support synchronious requests
    */
    supportsSyncRequests(): boolean;

    /**
     * Stores the value into the storage using the specified key.
     * @param key - The key value to use for the value
     * @param evt - The actual event of the request
     * @param itemCtx - This is the context for the current request, ITelemetryPlugin instances
     * can optionally use this to access the current core instance or define / pass additional information
     * to later plugins (vs appending items to the telemetry item)
     * @returns Either the added element (for synchronous operation) or a Promise for an asynchronous processing
     */
    addEvent(key: string, evt: IStorageTelemetryItem, itemCtx: IProcessTelemetryContext): IStorageTelemetryItem | IPromise<IStorageTelemetryItem> | null;

    /**
     * Get Next batch from the storage
     */
     getNextBatch(): IStorageTelemetryItem[] | IPromise< IStorageTelemetryItem[]> | null;

     /**
     * Get all stored batches from the storage.
     * @param cnt - batch numbers if it is defined, it will returns given number of batches.
     * if cnt is not defined, it will return all available batches
     */
     getAllEvents(cnt?: number): IStorageTelemetryItem[] | IPromise< IStorageTelemetryItem[]> | null;
   
    /**
     * Removes the value associated with the provided key
     * @param evts - The events to be removed
     * @returns Either the removed item array (for synchronous operation) or a Promise for an asynchronous processing
     */
    removeEvents(evts: IStorageTelemetryItem[]): IStorageTelemetryItem[] | IPromise<IStorageTelemetryItem[]> | null;

    /**
     * Removes all entries from the storage provider, if there are any.
     * @returns Either the removed item array (for synchronous operation) or a Promise for an asynchronous processing
     */
    clear(): IStorageTelemetryItem[] | IPromise<IStorageTelemetryItem[]> | null;

    /**
     * Removes all entries with stroage time longer than inStorageMaxTime from the storage provider
     */
    clean(disable?: boolean): boolean | IPromise<boolean>;

    /**
     * Shuts-down the telemetry plugin. This is usually called when telemetry is shut down.
     */
    teardown(): void;
}

/**
* Checks if the value is a valid EventPersistence.
* @param {enum} value - The value that needs to be checked.
* @returns {boolean} True if the value is in EventPersistence, false otherwise.
*/
export function isValidPersistenceLevel(value: EventPersistence | number): boolean {
    return (isNumber(value) && value >= eLoggingSeverity.DISABLED && value <= EventPersistence.Critical);
}


// Endpoint schema
// <prefix>.<suffix>
//Prefix: Defines a service.
//Suffix: Defines the common domain name.

/**
 * Get domian from an endpoint url.
 * for example, https://test.com?auth=true, will return test.com
 * @param endpoint - endpoint url
 * @returns domain string
 */
export function getEndpointDomain(endpoint: string) {
    try {
        let url = endpoint.replace(/^https?:\/\/|^www\./, "");
        url = url.replace(/\?/, "/");
        let arr = url.split("/");
        if (arr && arr.length > 0) {
            return arr[0];
        }
      
    } catch (e) {
        // eslint-disable-next-line no-empty
    }
    // if we can't get domain, entire endpoint will be used
    return endpoint;
}

/**
 * If current value is equal or greater than zero.
 * @param value - number
 * @returns boolean
 */
export function isGreaterThanZero(value: number) {
    return value >= 0;
}


//Base64 is a binary encoding rather than a text encoding,
// it were added to the web platform before it supported binary data types.
// As a result, the two functions use strings to represent binary data
const _base64 = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=";
/**
 * Base64-encodes a Uint8Array.
 *
 * @param data - the Uint8Array or string to encode.
 *
 * @returns the base64-encoded output string.
 */
export function base64Encode(data: string | Uint8Array) {
    let line = "";
    let input = "";

    if (isString(data)) {
        input = data;
    } else {
        input = data.toString();
    }

    let output = "";
    // tslint:disable-next-line:one-variable-per-declaration
    let chr1, chr2, chr3;

    let lp = 0;
    while (lp < input.length) {
        chr1 = input.charCodeAt(lp++);
        chr2 = input.charCodeAt(lp++);
        chr3 = input.charCodeAt(lp++);

        // encode 4 character group
        line += _base64.charAt(chr1 >> 2);
        line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));
        if (isNaN(chr2)) {
            line += "==";
        } else {
            line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));
            line += isNaN(chr3) ? "=" : _base64.charAt(chr3 & 63);
        }
    }

    output += line;

    return output;
}

/**
 * Base64-decodes an encoded string and transforms it back to a Uint8Array.
 * @param input - the encoded string to decode
 * @returns  Uint8Array
 */
export function base64Decode(input: string) {
    var output = "";
    var chr1, chr2, chr3;
    var enc1, enc2, enc3, enc4;
    var i = 0;

    input = input.replace(/[^A-Za-z0-9\+\/\=]/g, "");

    while (i < input.length) {

        enc1 = _base64.indexOf(input.charAt(i++));
        enc2 = _base64.indexOf(input.charAt(i++));
        enc3 = _base64.indexOf(input.charAt(i++));
        enc4 = _base64.indexOf(input.charAt(i++));

        chr1 = (enc1 << 2) | (enc2 >> 4);
        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);
        chr3 = ((enc3 & 3) << 6) | enc4;

        output = output + String.fromCharCode(chr1);

        if (enc3 != 64) {
            output = output + String.fromCharCode(chr2);
        }
        if (enc4 != 64) {
            output = output + String.fromCharCode(chr3);
        }

    }
    let arr = output.split(",").map(c => Number(c));
    return new Uint8Array(arr);

}

/**
 * Get number value of current time and append a random float number.
 * For example, if current time value is 12345678, so "12345678.randomfl" will be returned
 * @returns time id string
 */
export function getTimeId(): string {
    let time = (new Date()).getTime();
    // append random digits to avoid same timestamp value
    const random = strSubstr(generateW3CId(), 0, 8);
    // function to create spanid();
    return time + "." + random;
}

/**
 * Get time value from a time id that is generated from getTimeId() function.
 * For example, if time id is "12345678.randomfl", 12345678 will be returned
 * @param id - time id string
 * @returns time value number
 */
export function getTimeFromId(id: string) {
    try {
        let regex = new RegExp(/\d+\./g);
        if (id && isString(id) && regex.test(id)) {
            let arr = id.split(".");
            return parseInt(arr[0]);
 
        }
    } catch (e) {
        // eslint-disable-next-line no-empty
    }
    return 0;
}

/**
 * Get persistence level from a telemetry item.
 * Persistence level will be get from root, baseData or data in order.
 * For example, if persistence level is set both in root and baseData, the root one will be returned.
 * If no valid persistence level defined, normal level will be returned.
 * @param item - telemetry item
 * @returns persistent level
 */
export function getPersistence(item: ITelemetryItem | IPostTransmissionTelemetryItem): number | EventPersistence {
    let rlt = EventPersistence.Normal;
    // if item is null, return normal level
    if (!item) {
        return rlt;
    }
    try {
        let iItem = item as IPostTransmissionTelemetryItem;
        let level = iItem.persistence || (iItem.baseData && iItem.baseData.persistence) || (iItem.data && iItem.data.persistence);
        if (level && isValidPersistenceLevel(level)) {
            return level;
        }
    } catch (e) {
        // eslint-disable-next-line no-empty
    }
    return rlt;
}

export const EVT_DISCARD_STR = "eventsDiscarded";
export const EVT_STORE_STR = "offlineEventsStored";
export const EVT_SENT_STR = "offlineBatchSent";
export const BATCH_DROP_STR = "offlineBatchDrop";

export function forEachMap<T>(map: { [key: string]: T }, callback: (value: T, key: string) => boolean, ordered?: boolean): void {
    if (map) {
        let keys = objKeys(map);
        if (!!ordered && keys) {
            let time = (new Date()).getTime();
            keys = keys.sort((a,b) => {
                try {
                    // if getTimeFromId returns 0, mean the time is not valid
                    let aTime = getTimeFromId(a) || time;
                    let bTime = getTimeFromId(b) || time;
                    return aTime - bTime;
                } catch(e) {
                    // eslint-disable-next-line no-empty
                }
                return -1;
            });
        }
        for (let lp = 0; lp < keys.length; lp++) {
            let key = keys[lp];
            if (!callback(map[key], key)) {
                break;
            }
        }
    }
}

 
export function callNotification(mgr: INotificationManager, evtName: string, theArgs: any[]) {
    let manager = (mgr || ({} as NotificationManager));
    let notifyFunc = manager[evtName];
    if (notifyFunc) {
        try {
            notifyFunc.apply(manager, theArgs);
        } catch (e) {
            // eslint-disable-next-line no-empty
        }
    }
}

export function batchDropNotification(mgr: INotificationManager, cnt: number, reason?: number) {
    if (mgr && cnt > 0) {
        callNotification(mgr, BATCH_DROP_STR, [cnt, reason]);
    }
    return;
}





// OneCollector:
// 200-OK – Success or partial success.
// 204-NoContent – Success or partial success. Regarding accepting events, identical to 200-OK. If the request header contains NoResponseBody with the value of true and the request was successful/partially successful, 204-NoContent status code is returned instead of 200-OK.
// 400-BadRequest – all events were rejected.
// 403-Forbidden – client is above its quota and all events were throttled.
// 413-RequestEntityTooLarge – the request doesn’t conform to limits described in Request constraints section.
// 415-UnsupportedMediaType – the Content-Type or Content-Encoding header has an unexpected value.
// 429-TooManyRequests – the server decided to throttle given request (no data accepted) as the client (device, client version, …) generates too much traffic.
// 401-Unauthorized – Can occur under two conditions:
//   All tenant tokens included in this request are invalid (unauthorized). kill-tokens header indicates which one(s). WWW-Authenticate: Token realm="ingestion" (see: rfc2617 for more details) header is added.
// The client has supplied the “strict” header (see section 3.3), and at least one MSA and/or XAuth event token cannot be used as a source of trusted user or device information.  The event failure reason “TokenCrackingFailure” will be present in the response’ JSON body.  In this scenario, the client is expected to fix or replace the offending ticket and retry.
// 500-InternalServerError – an unexpected exception while handling the request.
// 503-ServiceUnavailable – a machine serving this request is overloaded or shutting down. The request should be retried to a different machine. The server adds Connection: Close header to enforce TCP connection closing.



// Breeze
// 0 ad blockers
// 200 Success!
// 206 - Partial Accept
// 307/308 - Redirect
// 400 - Invalid
//  400 can also be caused by Azure AD authentication.
//  400 is not retriable and SDK should drop invalid data.
// 401 - Unauthorized
//  401 can be also caused by an AAD outage.
//  401 is retriable.
// 402 - Daily Quota Exceeded, drop the data.
//  There is no retry-after in the response header for 402.
// 403 - Forbidden
//  403 can also caused by misconfiguring the access control assigned to the Application Insights resource.
//  403 is retriable.
// 404 - Ingestion is allowed only from stamp specific endpoint
//  Telemetry will be dropped and customer must update their connection string.
//  404 is not retriable and SDK should drop the data.
// 408 - Timeout, retry it later. (offline might get this)
// 429 - Too Many Requests, Breeze returns retry-after for status code 429 only.
// 500 - Internal Server Error, retry it later.
// 502 - Bad Gateway, retry it later.
// 503 - Service Unavailable, retry it later. (offline)
// 504 - Gateway timeout, retry it later.
// All other response codes, SDK should drop the data.


//TODO: move all const to one file
const EventsToDropAtOneTime = 10;
const Version = "1";
const DefaultStorageKey = "AIOffline";
const DefaultMaxStorageSizeInBytes = 5000000;
const MaxCriticalEvtsDropCnt = 2;
const DefaultMaxInStorageTime = 604800000; //7*24*60*60*1000 7days
// [Optional for version 1]: TODO: order event by time

interface IJsonStoreDetails {
    key: string;
    db: IStorageJSON;
}

// Private helper methods that are not exposed as class methods
function _isQuotaExceeded(storage: Storage, e) {
    let result = false;
    if (e instanceof DOMException) {
        // test name field too, because code might not be present
        if (e.code === 22 || e.name === "QuotaExceededError" ||            // everything except Firefox
            e.code === 1014 || e.name === "NS_ERROR_DOM_QUOTA_REACHED") {   // Firefox
            if (storage && storage.length !== 0) {
                // acknowledge QuotaExceededError only if there's something already stored
                result = true;
            }
        }
    }

    return result;
}

/**
* Check and return that the storage type exists and has space to use
*/
function _getAvailableStorage(type: string): Storage {
    let global = getGlobal() || ({} as Window);
    let storage: Storage = null;
    try {
        storage = ((global[type]) as Storage);
        if (storage) {
            let x = "__storage_test__";
            storage.setItem(x, x);
            storage.removeItem(x);
        }
    } catch (e) {
        if (!_isQuotaExceeded(storage, e)) {
            // If not Quota exception then assume not available
            storage = null;
        }
    }

    return storage;
}


// will drop batches with no critical evts first
function _dropEventsUpToPersistence(
    maxCnt: number,
    events: { [id: string]: IStorageTelemetryItem },
    eventsToDropAtOneTime: number): number {
    let dropKeys = [];
    let persistenceCnt = 0;
    let droppedEvents = 0;
    while (persistenceCnt <= maxCnt && droppedEvents < eventsToDropAtOneTime) {
        forEachMap<IStorageTelemetryItem>(events, (evt, key) => {
            if (evt.criticalCnt === persistenceCnt) {
                dropKeys.push(key);
                droppedEvents++;
            }
            return (droppedEvents < eventsToDropAtOneTime);
        });
        if (droppedEvents > 0) {
            for (let lp = 0; lp < dropKeys.length; lp++) {
                delete events[dropKeys[lp]];
            }
            return droppedEvents;
        }

        persistenceCnt++;
    }

    return droppedEvents;
}

function _dropMaxTimeEvents(
    maxStorageTime: number,
    events: { [id: string]: IStorageTelemetryItem },
    eventsToDropAtOneTime: number,
    mgr?: INotificationManager): boolean {
    let dropKeys = [];
    let droppedEvents = 0;
    let currentTime = (new Date()).getTime() + 1; // handle appended random float number
    let minStartTime = (currentTime - maxStorageTime);
    try {
        forEachMap<IStorageTelemetryItem>(events, (evt, key) => {
            let id = getTimeFromId(key);
            if (id <= minStartTime) {
                dropKeys.push(key);
                droppedEvents++;
            }
            return (droppedEvents < eventsToDropAtOneTime);
        });
    
        if (droppedEvents > 0) {
            for (let lp = 0; lp < dropKeys.length; lp++) {
                delete events[dropKeys[lp]];
            }
            if (mgr) {
                batchDropNotification(mgr, droppedEvents, eBatchDiscardedReason.MaxInStorageTimeExceeded);
            }
           
            return true;
        }

    } catch (e) {
        // catch drop events error
    }

    return droppedEvents > 0;
}



/**
 * Class that implements storing of events using the WebStorage Api ((window||globalThis||self).localstorage, (window||globalThis||self).sessionStorage).
 */
export class WebStorageProvider implements IOfflineProvider {
    public id: string;

    /**
     * Creates a WebStorageProvider using the provider storageType
     * @param storageType - The type of Storage provider, normal values are "localStorage" or "sessionStorage"
     */
    constructor(storageType: string, id?: string, unloadHookContainer?: IUnloadHookContainer) {
        dynamicProto(WebStorageProvider, this, (_this) => {
            let _storage: Storage = null;
            let _storageKeyPrefix: string = DefaultStorageKey;
            let _maxStorageSizeInBytes: number = DefaultMaxStorageSizeInBytes;
            let _payloadHelper: PayloadHelper = null;
            let _storageKey: string = null;
            let _endpoint: string = null;
            let _maxStorageTime: number = null;
            let _eventDropPerTime: number = null;
            let _maxCriticalCnt: number = null;
            let _notificationManager: INotificationManager = null;

            _this.id = id;

            _storage = _getAvailableStorage(storageType) || null;

            _this["_getDbgPlgTargets"] = () => {
                return [_storageKey, _maxStorageSizeInBytes, _maxStorageTime];
            };

            _this.initialize = (providerContext: ILocalStorageProviderContext, endpointUrl?: string) => {
                if (!_storage) {
                    return false;
                }
               
                let storageConfig: IOfflineChannelConfiguration = providerContext.storageConfig;
                let itemCtx = providerContext.itemCtx;
                _payloadHelper = new PayloadHelper(itemCtx.diagLog());
                _endpoint = getEndpointDomain(endpointUrl || providerContext.endpoint);
                let autoClean = !!storageConfig.autoClean;
                _notificationManager = providerContext.notificationMgr;

                let unloadHook = onConfigChange(storageConfig, () => {
                    _maxStorageSizeInBytes = storageConfig.maxStorageSizeInBytes || DefaultMaxStorageSizeInBytes; // value checks and defaults should be applied during core config
                    _maxStorageTime = storageConfig.inStorageMaxTime || DefaultMaxInStorageTime; // TODO: handle 0
                    let dropNum = storageConfig.EventsToDropPerTime;
                    _eventDropPerTime = isNotNullOrUndefined(dropNum)? dropNum : EventsToDropAtOneTime;
                    _maxCriticalCnt = storageConfig.maxCriticalEvtsDropCnt || MaxCriticalEvtsDropCnt;
                  
                });
                unloadHookContainer && unloadHookContainer.add(unloadHook);

                // currently, won't handle endpoint change here
                // new endpoint will open a new db
                // endpoint change will be handled at offline batch level
                // namePrefix should not contain any "_"
                _storageKeyPrefix = storageConfig.storageKeyPrefix || DefaultStorageKey;
                _storageKey = _storageKeyPrefix + "_" + Version + "_" + _endpoint;

                if (autoClean) {
                    // won't wait response here
                    _this.clean();
                }

                
                // TODO: handle versoin Upgrade
                //_checkVersion();
             

                return true;
            };

            /**
              * Identifies whether this storage provider support synchronous requests
             */
            _this.supportsSyncRequests = () => {
                return true;
            };

            /**
             * Get all of the currently cached events from the storage mechanism
             */
            _this.getAllEvents = (cnt?: number) => {
                try {
                    if (!_storage) {
                        // if not init, return null
                        return;
                    }
                    return _getEvts(cnt);
                    
                } catch (e) {
                    return createAsyncRejectedPromise(e);
                }
            };

            
            /**
             * Get Next cached event from the storage mechanism
             */
            _this.getNextBatch = () => {
                try {
                    if (!_storage) {
                        // if not init, return null
                        return;
                    }
                    // set ordered to true, to make sure to get earliest events first
                    return _getEvts(1, true);
                    
                } catch (e) {
                    return createAsyncRejectedPromise(e);
                }
            };

            function _getEvts(cnt?: number, ordered?: boolean) {
                let allItems: IStorageTelemetryItem[] = [];
                let theStore = _fetchStoredDb(_storageKey).db;
                if (theStore) {
                    let events = theStore.evts;
                    forEachMap(events, (evt) => {
                        if (evt) {
                            if (evt.isArr) {
                                evt = _payloadHelper.base64ToArr(evt);
                            }
                            allItems.push(evt);
                        }
                        if(cnt && allItems && allItems.length == cnt) {
                            return false;
                        }
                        return true;
                    }, ordered);
                }
                return  allItems;
                    
            }


            /**
             * Stores the value into the storage using the specified key.
             * @param key - The key value to use for the value
             * @param value - The actual value of the request
             */
            _this.addEvent = (key: string, evt: IStorageTelemetryItem, itemCtx: IProcessTelemetryContext)  => {
                try {
                    let theStore = _fetchStoredDb(_storageKey);
                    evt.id = evt.id || getTimeId();
                    evt.criticalCnt = evt.criticalCnt || 0;
                    let events = theStore.db.evts;
                    let id = evt.id;
                    if (evt && evt.isArr) {
                        evt = _payloadHelper.base64ToStr(evt);
                    }
                    let preDroppedCnt = 0;

                    // eslint-disable-next-line no-constant-condition
                    while (true && evt) {
                        events[id] = evt;
                        if (_updateStoredDb(theStore)) {
                            // Database successfully updated
                            if (preDroppedCnt && _notificationManager) {
                                // only send notification when batches are updated successfully in storage
                                batchDropNotification(_notificationManager, preDroppedCnt, eBatchDiscardedReason.CleanStorage);
                            }
                            return evt;
                        }

                        // Could not not add events to storage assuming its full, so drop events to make space
                        // or max size exceeded
                        delete events[id];
                        let droppedCnt = _dropEventsUpToPersistence(_maxCriticalCnt, events, _eventDropPerTime);
                        preDroppedCnt += droppedCnt;
                        if (!droppedCnt) {
                            // Can't free any space for event
                            return createAsyncRejectedPromise(new Error("Unable to free up event space"));
                        }
                    }
                } catch (e) {
                    return createAsyncRejectedPromise(e);
                }
            };

            /**
             * Removes the value associated with the provided key
             * @param evts - The events to be removed
             */
            _this.removeEvents = (evts: IStorageTelemetryItem[]) => {
                try {
                    let theStore = _fetchStoredDb(_storageKey, false);
                    let currentDb = theStore.db;
                    if (currentDb) {
                        let events = currentDb.evts;
                        try {
                            for (let i = 0; i < evts.length; ++i) {
                                let evt = evts[i];
                                delete events[evt.id];
                            }

                            // Update takes care of removing the DB if it's completely empty now
                            if (_updateStoredDb(theStore)) {
                                return evts;
                            }
                        } catch (e) {
                            // Storage corrupted
                        }

                        // failure here so try and remove db to unblock following events
                        evts = _clearDatabase(theStore.key);
                        
                    }

                    return evts;
                } catch (e) {
                    return createAsyncRejectedPromise(e);
                }
            };

            /**
             * Removes all entries from the storage provider for the current endpoint and returns them as part of the response, if there are any.
             */
            _this.clear = () => {
                try {
                    let removedItems: IStorageTelemetryItem[] = [];
                    let theStore = _fetchStoredDb(_storageKey, false);
                    let storedDb = theStore.db;
                    if (storedDb) {
                        let events = storedDb.evts;
                        forEachMap(events, (evt) => {
                            if (evt) {
                                delete events[evt.id]
                                removedItems.push(evt);
                            }

                            return true;
                        });

                        _updateStoredDb(theStore);
                    }

                    return removedItems;
                } catch (e) {
                    // Unable to clear the database
                    return createAsyncRejectedPromise(e);
                }
            };

            _this.clean = () => {
                let storeDetails = _fetchStoredDb(_storageKey, false);
                let currentDb = storeDetails.db;
                if (currentDb) {
                    let events = currentDb.evts;
                    try {
                        let isDropped = _dropMaxTimeEvents(_maxStorageTime, events, _eventDropPerTime, _notificationManager);
                        if (isDropped) {
                            return _updateStoredDb(storeDetails);
                        }
                        return true;
                        
                    } catch (e) {
                        // should not throw errors here
                        // because we don't want to block following process
                    }
                    return false;
                }

            };

            /**
             * Shuts-down the telemetry plugin. This is usually called when telemetry is shut down.
             * This attempts to update the lastAccessTime for any storedDb
             */
            _this.teardown = (): void => {
                try {
                    let theStore = _fetchStoredDb(_storageKey, false);
                    let storedDb = theStore.db;
                    if (storedDb) {
                        // reset the last access time
                        storedDb.lastAccessTime = 0;
                        _updateStoredDb(theStore, false);
                    }
                } catch (e) {
                    // Add diagnostic logging
                }
            };

            /**
             * @ignore
             * Creates a new json store with the StorageJSON (may be null), a null db value indicates that the store
             * associated with the key is empty and should be removed.
             * @param dbKey - The key to associate with the database
             * @param db - The database
             */
            function _newStore(dbKey: string, db: IStorageJSON): IJsonStoreDetails {
                return {
                    key: dbKey,
                    db: db
                };
            }

            function _fetchStoredDb(dbKey: string, returnDefault = true): IJsonStoreDetails {
                let dbToStore: IStorageJSON = null;
                if (_storage) {
                    let previousDb = _storage.getItem(dbKey);
                 
                    if (previousDb) {
                        try {
                            dbToStore = getJSON().parse(previousDb);
                        } catch (e) {
                            // storage corrupted
                            _storage.removeItem(dbKey);
                        }
                    }

                    if (returnDefault && !dbToStore) {
                        // Create and return a default empty database
                        dbToStore = {
                            evts: {},
                            lastAccessTime: 0
                        };
                    }
                }

                return _newStore(dbKey, dbToStore);
            }

            function _updateStoredDb(jsonStore: IJsonStoreDetails, updateLastAccessTime = true): boolean {
                //let removeDb = true;
                let dbToStore = jsonStore.db;
                if (dbToStore) {
                    if (updateLastAccessTime) {
                        // Update the last access time
                        dbToStore.lastAccessTime = (new Date()).getTime();
                    }
                }

                try {

                    let jsonString = getJSON().stringify(dbToStore);
                    if (jsonString.length > _maxStorageSizeInBytes) {
                        // We can't store the database as it would exceed the configured max size
                        return false;
                    }

                    _storage && _storage.setItem(jsonStore.key, jsonString);
                    //}
                } catch (e) {
                    // catch exception due to trying to store or clear JSON
                    // We could not store the database
                    return false;
                }

                return true;
            }

            function _clearDatabase(dbKey: string): IStorageTelemetryItem[] {
                let removedItems: IStorageTelemetryItem[] = [];
                let storeDetails = _fetchStoredDb(dbKey, false);
                let currentDb = storeDetails.db;
                if (currentDb) {
                    let events = currentDb.evts;
                    try {
                        forEachMap(events, (evt) => {
                            if (evt) {
                                removedItems.push(evt);
                            }

                            return true;
                        });
                        
                    } catch (e) {
                        // catch exception due to trying to store or clear JSON
                    }

                    // Remove the entire stored database
                    _storage && _storage.removeItem(storeDetails.key);
                }

                return removedItems;
            }

        });
    }

    /**
     * Initializes the provider using the config
     * @param providerContext - The provider context that should be used to initialize the provider
     * @returns True if the provider is initialized and available for use otherwise false
     */
    public initialize(providerContext: ILocalStorageProviderContext): boolean {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return false;
    }

    /**
     * Identifies whether this storage provider support synchronous requests
    */
    public supportsSyncRequests(): boolean {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return false;
    }

    /**
     * Get all of the currently cached events from the storage mechanism
     */
    public getAllEvents(cnt?: number): IStorageTelemetryItem[] | IPromise< IStorageTelemetryItem[]> | null {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return null;
    }

    /**
     * Get the Next one cached batch from the storage mechanism
     */
    public getNextBatch(): IStorageTelemetryItem[] | IPromise< IStorageTelemetryItem[]> | null {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return null;
    }


    /**
     * Stores the value into the storage using the specified key.
     * @param key - The key value to use for the value
     * @param evt - The actual event of the request
     * @param itemCtx - This is the context for the current request, ITelemetryPlugin instances
     * can optionally use this to access the current core instance or define / pass additional information
     * to later plugins (vs appending items to the telemetry item)
     */
    public addEvent(key: string, evt: any, itemCtx: IProcessTelemetryContext): IStorageTelemetryItem | IPromise<IStorageTelemetryItem> | null {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return;
    }

    /**
     * Removes the value associated with the provided key
     * @param evts - The events to be removed
     */
    public removeEvents(evts: any[]): IStorageTelemetryItem[] | IPromise<IStorageTelemetryItem[]> | null {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return;
    }

    /**
     * Removes all entries from the storage provider, if there are any.
     */
    public clear(): IStorageTelemetryItem[] | IPromise<IStorageTelemetryItem[]> | null {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return;
    }

    /**
     * Removes all entries with stroage time longer than inStorageMaxTime from the storage provider
     */
    public clean(): boolean | IPromise<boolean> {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
        return;
    }

    /**
     * Shuts-down the telemetry plugin. This is usually called when telemetry is shut down.
     */
    public teardown(): void {
        // @DynamicProtoStub - DO NOT add any code as this will be removed during packaging
    }
}